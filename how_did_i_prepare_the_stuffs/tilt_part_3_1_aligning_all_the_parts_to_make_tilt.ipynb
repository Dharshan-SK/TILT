{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdtYJJE/gqRdJD2aJ7nI9l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "250938dfb71d45e0858cd757df64cd8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20ea30cbafb84c618979bd41e8d921d6",
              "IPY_MODEL_ff6f0b419450464a9daf73a41e357930",
              "IPY_MODEL_681f7ed3e39442cd8f987db7a131f4e1"
            ],
            "layout": "IPY_MODEL_33af6b7b9d7e4c8d90a9e4d66159f951"
          }
        },
        "20ea30cbafb84c618979bd41e8d921d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3959923118c84010b4b0024b28ca2734",
            "placeholder": "​",
            "style": "IPY_MODEL_b3fd33e82ba7455981c0499df81cb0d5",
            "value": "100%"
          }
        },
        "ff6f0b419450464a9daf73a41e357930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59955fdf275549ca8873c9b053419fd7",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e288264d36f49c58f09b95ae3587e26",
            "value": 2
          }
        },
        "681f7ed3e39442cd8f987db7a131f4e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66bcfafd26e14fb8b333d0da2efc222f",
            "placeholder": "​",
            "style": "IPY_MODEL_c3deff7939634161bca16addf85406a4",
            "value": " 2/2 [00:00&lt;00:00, 21.71it/s]"
          }
        },
        "33af6b7b9d7e4c8d90a9e4d66159f951": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3959923118c84010b4b0024b28ca2734": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3fd33e82ba7455981c0499df81cb0d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59955fdf275549ca8873c9b053419fd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e288264d36f49c58f09b95ae3587e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66bcfafd26e14fb8b333d0da2efc222f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3deff7939634161bca16addf85406a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uakarsh/TiLT-Implementation/blob/main/how_did_i_prepare_the_stuffs/tilt_part_3_1_aligning_all_the_parts_to_make_tilt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15ohrRAbDZ4v",
        "outputId": "5d5eec1e-0227-45c0-c9f8-337e02486c1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'TiLT-Implementation' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/uakarsh/TiLT-Implementation.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/TiLT-Implementation/requirements.txt"
      ],
      "metadata": {
        "id": "IlsCNhv3D0hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/TiLT-Implementation/src/\")"
      ],
      "metadata": {
        "id": "1W4eZnAcD3Pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoConfig\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from dataset import FUNSDDs\n",
        "from torchvision import transforms\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "## Custom imports\n",
        "from visual_backbone import Unet_encoder, RoIPool\n",
        "from t5 import T5ForConditionalGeneration, T5Stack\n",
        "from transformers import AutoModel"
      ],
      "metadata": {
        "id": "hshzmmrID39p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Preparing the dataset"
      ],
      "metadata": {
        "id": "uPeVZmMeEbyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "hf_ds = load_dataset(\"nielsr/funsd-layoutlmv3\")\n",
        "model_name = \"t5-base\"\n",
        "## Visual Embedding extractor's parameters\n",
        "in_channels = 3\n",
        "num_pool_layers = 3\n",
        "channels = 16\n",
        "sampling_ratio = 2\n",
        "spatial_scale = 48 / 384\n",
        "output_size = (3,3)\n",
        "load_weights = True\n",
        "\n",
        "## Tokenizer's parameter\n",
        "model_max_length = 512\n",
        "\n",
        "t5_config = AutoConfig.from_pretrained(model_name)\n",
        "## Adding new parameters\n",
        "t5_config.update(dict(in_channels = in_channels, num_pool_layers = num_pool_layers,  channels = channels, model_max_length = model_max_length,\n",
        "                      output_size = output_size, spatial_scale = spatial_scale, sampling_ratio = sampling_ratio, use_cache = False, load_weights = load_weights))\n",
        "\n",
        "## Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast = True, model_max_length = model_max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "250938dfb71d45e0858cd757df64cd8b",
            "20ea30cbafb84c618979bd41e8d921d6",
            "ff6f0b419450464a9daf73a41e357930",
            "681f7ed3e39442cd8f987db7a131f4e1",
            "33af6b7b9d7e4c8d90a9e4d66159f951",
            "3959923118c84010b4b0024b28ca2734",
            "b3fd33e82ba7455981c0499df81cb0d5",
            "59955fdf275549ca8873c9b053419fd7",
            "5e288264d36f49c58f09b95ae3587e26",
            "66bcfafd26e14fb8b333d0da2efc222f",
            "c3deff7939634161bca16addf85406a4"
          ]
        },
        "id": "qzcvnEyYD-KC",
        "outputId": "a7f9bab8-de97-400c-edbf-36ba169ab33d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset funsd-layoutlmv3 (/root/.cache/huggingface/datasets/nielsr___funsd-layoutlmv3/funsd/1.0.0/0e3f4efdfd59aa1c3b4952c517894f7b1fc4d75c12ef01bcc8626a69e41c1bb9)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "250938dfb71d45e0858cd757df64cd8b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_id2label_and_label2id():\n",
        "    label2id = {'O': 0, 'B-HEADER': 1, 'I-HEADER': 2, 'B-QUESTION': 3, 'I-QUESTION': 4, 'B-ANSWER': 5, 'I-ANSWER': 6}\n",
        "    id2label = {0: 'O', 1: 'B-HEADER', 2: 'I-HEADER', 3: 'B-QUESTION', 4: 'I-QUESTION', 5: 'B-ANSWER', 6: 'I-ANSWER'}\n",
        "    return id2label, label2id\n",
        "\n",
        "def convert_id_to_label(list_of_label):\n",
        "  return [id2label[x] for x in list_of_label]"
      ],
      "metadata": {
        "id": "DOzw5T71EJtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label, label2id = get_id2label_and_label2id()\n",
        "transform = transforms.Compose([transforms.ToTensor(), \n",
        "                                transforms.Lambda(lambda x : 2 * x - 1)])"
      ],
      "metadata": {
        "id": "tObzBFUUEFGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_new_tags = list(map(lambda x : convert_id_to_label(x), hf_ds['train']['ner_tags']))\n",
        "test_new_tags = list(map(lambda x : convert_id_to_label(x), hf_ds['test']['ner_tags']))"
      ],
      "metadata": {
        "id": "2x4vv43XEOKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_ds['train'] = hf_ds['train'].remove_columns(\"ner_tags\").add_column(\"ner_tags\", train_new_tags)\n",
        "hf_ds['test'] = hf_ds['test'].remove_columns(\"ner_tags\").add_column(\"ner_tags\", test_new_tags)"
      ],
      "metadata": {
        "id": "UcmRobRhEQ0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = FUNSDDs(hf_ds['train'],tokenizer = tokenizer, transform = transform)\n",
        "val_ds = FUNSDDs(hf_ds['test'],tokenizer = tokenizer, transform = transform)"
      ],
      "metadata": {
        "id": "cknoT_1YEQ9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Writing the `collate_fn` for custom handling of the dataloader"
      ],
      "metadata": {
        "id": "8bHthQUuEeVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CollateFn(object):\n",
        "  def __init__(self, tokenizer):\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def __call__(self, list_of_ds):\n",
        "    simple_keys = [\"input_ids\", \"attention_mask\", \"bboxes\", \"pixel_values\" ]\n",
        "    actual_batch = {}\n",
        "    for key in simple_keys:\n",
        "      actual_batch[key] = torch.stack([x[key] for x in list_of_ds])\n",
        "    \n",
        "    actual_batch['labels'] = self.tokenizer.batch_encode_plus([x['labels'] for x in list_of_ds], return_tensors = 'pt', is_split_into_words = True,\n",
        "                                                              padding='max_length', truncation = True)['input_ids']\n",
        "    return actual_batch"
      ],
      "metadata": {
        "id": "fchZF6hxESY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collate_fn = CollateFn(tokenizer)"
      ],
      "metadata": {
        "id": "HqlPfz8TET7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_batch_encoding = collate_fn([train_ds[0], train_ds[1]])\n",
        "# for key in sample_batch_encoding:\n",
        "#   sample_batch_encoding[key] = sample_batch_encoding[key].to(device)\n",
        "# #   print(f\"Key : {key}, has shape : {sample_batch_encoding[key].shape}\")"
      ],
      "metadata": {
        "id": "m26xnsfXEVFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Preparing the visual model"
      ],
      "metadata": {
        "id": "u5qhZ38OGQDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VisualEmbedding(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.unet_encoder = Unet_encoder(in_channels = config.in_channels, channels = config.channels, num_pool_layers = config.num_pool_layers)\n",
        "    self.roi_pool = RoIPool(output_size = config.output_size, spatial_scale = config.spatial_scale)\n",
        "    self.proj = nn.Linear(in_features = 128 * 3 * 3, out_features = config.d_model)\n",
        "    self.config = config\n",
        "\n",
        "  def forward(self, pixel_values, bboxes):\n",
        "    image_embedding = self.unet_encoder(pixel_values)\n",
        "    feature_maps_bboxes = self.roi_pool(image_embedding, bboxes).flatten(2)\n",
        "    projection = self.proj(feature_maps_bboxes)\n",
        "    return projection"
      ],
      "metadata": {
        "id": "_cVQaYBUEZbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visual_embedding_extractor = VisualEmbedding(t5_config).to(device)"
      ],
      "metadata": {
        "id": "-24G_PZ7iBKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visual_embedding = visual_embedding_extractor(pixel_values = sample_batch_encoding['pixel_values'], bboxes = sample_batch_encoding['bboxes'])"
      ],
      "metadata": {
        "id": "yjDdffEsjJiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Preparing the semantic model"
      ],
      "metadata": {
        "id": "jdJzjR8elcoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# t5_model = T5ForConditionalGeneration(t5_config).to(device)"
      ],
      "metadata": {
        "id": "hBUB23n6lrD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Forward method\n",
        "\n",
        "# ## Semantic embedding from t5_model's embedding layer\n",
        "# semantic_embedding = t5_model.shared(sample_batch_encoding['input_ids'])\n",
        "\n",
        "# ## Net embedding is addition of both the embeddings\n",
        "# total_embedding = visual_embedding + semantic_embedding\n",
        "\n",
        "# ## This is then fed to t5_model\n",
        "# final_output = t5_model(attention_mask = sample_batch_encoding['attention_mask'], inputs_embeds = total_embedding,\n",
        "#                         labels = sample_batch_encoding['labels'])"
      ],
      "metadata": {
        "id": "wQGN4Y-FlvtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Some rough work\n",
        "\n",
        "# pretrained_t5_model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# for (name, param), (name_1, param_1) in zip(pretrained_t5_model.named_parameters(), t5_model.named_parameters()): \n",
        "#   if name.startswith(\"decoder\"):\n",
        "#     print(f\"{name}   {name_1}\")\n",
        "\n",
        "# t5_model_sd = t5_model.state_dict()\n",
        "# t5_model_sd_keys = t5_model_sd.keys()\n",
        "\n",
        "# pretrained_t5_model_sd = pretrained_t5_model.state_dict()\n",
        "# pretrained_t5_model_sd_keys = pretrained_t5_model_sd.keys()\n",
        "\n",
        "# t5_model_sd_keys = [k for k in t5_model_sd_keys if not any([\"relative_horizontal_bias\" in k, \"relative_vertical_bias\" in k])] # discard this mask / buffer, not a param\n",
        "\n",
        "# t5_model.load_state_dict(pretrained_t5_model.state_dict(), strict = False)"
      ],
      "metadata": {
        "id": "nKeRVrzSo6X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TiLTTransformer(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.config = config\n",
        "    self.visual_embedding_extractor = VisualEmbedding(config)\n",
        "    self.t5_model = T5ForConditionalGeneration(config)\n",
        "    \n",
        "\n",
        "  def generate(self, batch):\n",
        "    total_embedding = self.common_step(batch)\n",
        "    return self.t5_model.generate(input_embeds = total_embedding)\n",
        "\n",
        "  def common_step(self, batch):\n",
        "    ## Visual embedding\n",
        "    visual_embedding = self.visual_embedding_extractor(pixel_values = batch['pixel_values'], bboxes = batch['bboxes'])\n",
        "\n",
        "    ## Semantic embedding from t5_model's embedding layer\n",
        "    semantic_embedding = self.t5_model.shared(batch['input_ids'])\n",
        "\n",
        "    ## Net embedding is addition of both the embeddings\n",
        "    total_embedding = visual_embedding + semantic_embedding\n",
        "\n",
        "    return total_embedding\n",
        "\n",
        "  def forward(self, batch):\n",
        "\n",
        "    total_embedding = self.common_step(batch)\n",
        "\n",
        "    ## This is then fed to t5_model\n",
        "    final_output = self.t5_model(attention_mask = batch['attention_mask'], inputs_embeds = total_embedding,\n",
        "                            labels = batch['labels'])\n",
        "    \n",
        "    return final_output"
      ],
      "metadata": {
        "id": "SvWFMOIMDoaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tilt_model = TiLTTransformer(t5_config).to(device)\n",
        "# output = tilt_model(sample_batch_encoding)"
      ],
      "metadata": {
        "id": "vdJstn48Gnzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking out the parameters of all the models that have been mentioned in the paper"
      ],
      "metadata": {
        "id": "fTbS6zL0sLOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "T5_PRETRAINED_MODEL_ARCHIVE_LIST = [\n",
        "    \"t5-base\",\n",
        "    # \"t5-large\"\n",
        "]\n",
        "\n",
        "for model_name in T5_PRETRAINED_MODEL_ARCHIVE_LIST:\n",
        "  t5_config = AutoConfig.from_pretrained(model_name)\n",
        "  t5_config.update(dict(in_channels = in_channels, num_pool_layers = num_pool_layers,  channels = channels, model_max_length = model_max_length,\n",
        "                      output_size = output_size, spatial_scale = spatial_scale, sampling_ratio = sampling_ratio, use_cache = False, load_weights = load_weights))\n",
        "  tilt_model = TiLTTransformer(t5_config)\n",
        "  print(f\"Model : {model_name} has {sum(p.numel() for p in tilt_model.parameters()) / 1e6:.4f} M parameters\")"
      ],
      "metadata": {
        "id": "IjqpGJ8BHfdq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daa383cc-1942-4801-af19-30bbd7345d7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights loaded successfully!\n",
            "Model : t5-base has 224.2795 M parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In the paper, they reported: 230M and 780M, and we have got 225M and 740M, not sure, where am I missing, maybe in the visual backbone? But, I guess we can continue with this for now"
      ],
      "metadata": {
        "id": "_YJgtx7ow0-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import AutoModel\n",
        "# for model_name in T5_PRETRAINED_MODEL_ARCHIVE_LIST:\n",
        "#   tilt_model = AutoModel.from_pretrained(model_name)\n",
        "#   print(f\"Model : {model_name} has {sum(p.numel() for p in tilt_model.parameters()) / 1e6:.4f} M parameters\")"
      ],
      "metadata": {
        "id": "XbQBPo9Dsjdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GH8qxtCJtTvs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}